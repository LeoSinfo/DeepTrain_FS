{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "20baf805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c2e98da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d4494",
   "metadata": {},
   "source": [
    "# metaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3d1368f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ImgdataSet/cifar-10-batches-py/batches.meta'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b7ea684",
   "metadata": {},
   "source": [
    "classifer_list存放便是類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6e4dcede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cases_per_batch  = 10000\n",
      "lable = 0  | lable_name =b'airplane'\n",
      "lable = 1  | lable_name =b'automobile'\n",
      "lable = 2  | lable_name =b'bird'\n",
      "lable = 3  | lable_name =b'cat'\n",
      "lable = 4  | lable_name =b'deer'\n",
      "lable = 5  | lable_name =b'dog'\n",
      "lable = 6  | lable_name =b'frog'\n",
      "lable = 7  | lable_name =b'horse'\n",
      "lable = 8  | lable_name =b'ship'\n",
      "lable = 9  | lable_name =b'truck'\n",
      "\n",
      "num_vis  = 3072\n"
     ]
    }
   ],
   "source": [
    "meta_data = unpickle(path)#.keys()\n",
    "classifer_list = []\n",
    "print(\"num_cases_per_batch  = {}\".format(meta_data[b'num_cases_per_batch']))\n",
    "for i,t in zip(meta_data[b'label_names'],range(len(meta_data[b'label_names']))):\n",
    "    classifer_list.append((i,t))\n",
    "    print(\"lable = {}  | lable_name ={}\".format(t,i))\n",
    "print()\n",
    "print(\"num_vis  = {}\".format(meta_data[b'num_vis']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652c5f8",
   "metadata": {},
   "source": [
    "## data in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4b168f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_path = 'ImgdataSet/cifar-10-batches-py/'\n",
    "data_batch = ['data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "de5fe60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#將所有資料合成dict\n",
    "data = {}\n",
    "for i in data_batch:\n",
    "    temp = unpickle(pub_path+i)\n",
    "    data[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "18ab7a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5'])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "60a87f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch number : \n",
      "data_batch_1  |data_batch_2  |data_batch_3  |data_batch_4  |data_batch_5  |\n",
      "\n",
      "In one data_batch desc : \n",
      "b'batch_label'  |b'labels'  |b'data'  |b'filenames'  |"
     ]
    }
   ],
   "source": [
    "print('data_batch number : ')\n",
    "for i in data.keys():\n",
    "    print(i,end = '  |')\n",
    "print()\n",
    "print()\n",
    "print('In one data_batch desc : ')\n",
    "for i in data['data_batch_1'].keys():\n",
    "    print(i,end = '  |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b2a7c8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'leptodactylus_pentadactylus_s_000004.png'\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(data['data_batch_1'][b'filenames'][0])\n",
    "print(data['data_batch_1'][b'labels'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a1ff94",
   "metadata": {},
   "source": [
    "## data to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7e7f63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transImg(image):\n",
    "    image = np.array(image)\n",
    "    img = image.reshape((32, 32,3), order='F')\n",
    "    tensor = torch.from_numpy(img)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "38ed80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =transImg(data['data_batch_2'][b'data'][0])\n",
    "data2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a26beb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "87d2e090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(data['data_batch_2'][b'data'][0]))\n",
    "print(len(data['data_batch_2'][b'data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c7ee0c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch_1 0\n",
      "3072\n",
      "<class 'numpy.ndarray'>\n",
      "(3072,)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (32,32,3) into shape (3072,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-b7c771860826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         data[data_ind][b'data'][img_ind] = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (32,32,3) into shape (3072,)"
     ]
    }
   ],
   "source": [
    "for data_ind in data.keys():\n",
    "    \n",
    "    for img_ind in range(len(data[data_ind][b'data'])):\n",
    "        print(data_ind,img_ind)\n",
    "        print(len(data[data_ind][b'data'][img_ind]))\n",
    "        temp = transImg(data[data_ind][b'data'][img_ind])\n",
    "        print(type(data[data_ind][b'data'][img_ind]))\n",
    "        print(np.shape(data[data_ind][b'data'][img_ind]))\n",
    "#         data[data_ind][b'data'][img_ind] = []\n",
    "        print(type(temp))\n",
    "        data[data_ind][b'data'][img_ind] = temp\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b7ee4",
   "metadata": {},
   "source": [
    "## show picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c88b1f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'leptodactylus_pentadactylus_s_000004.png'\n",
      "[ 59  43  50 ... 140  84  72]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(data['data_batch_1'][b'filenames'][0])\n",
    "# print(data['data_batch_1'][b'labels'][0])\n",
    "img  = data['data_batch_1'][b'data'][0]\n",
    "class_num = data['data_batch_1'][b'labels'][0]\n",
    "print(img)\n",
    "print(class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f87cb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(image,class_num):\n",
    "    image = np.array(image)\n",
    "    img = image.reshape((32, 32,3), order='F')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Class is {}\".format(class_num))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dfe56c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImg(img,class_num)#v將圖案轉正"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6820f",
   "metadata": {},
   "source": [
    "# CNN in CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39836c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fcb901",
   "metadata": {},
   "source": [
    "## 超參數設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ca9f6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1        # 跑完幾次所有batchsize              \n",
    "BATCH_SIZE = 50  # 一次訓練的樣本數目\n",
    "LR = 0.001       #學習率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b69ce4e",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0551edaa",
   "metadata": {},
   "source": [
    "積卷核的通道數要和輸入要一樣，舉例來說(32, 32,3)是本次的圖片，共有RGB的深度，所以通道數為3\n",
    "* https://kvirajdatt.medium.com/calculating-output-dimensions-in-a-cnn-for-convolution-and-pooling-layers-with-keras-682960c73870\n",
    "* conv_size = (image_size-kernel_size+padding*2)/stride + 1\n",
    "* pool_size = (image_size-pooling_size)/2 + 1  && depth is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3901dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn_net,self).__init__()\n",
    "        # 建置各個類神經會用到的模組\n",
    "        # 定義一個卷積層 輸入深度為3 輸出深度16  kernel_size核大小3*3 stride步伐1 piex padding用於處理卷積的邊界情況 == stride (kernel_size-1)/2\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=2) #https://www.twblogs.net/a/5eec7f6b7301656afddaa356\n",
    "        # output_size =[(32-3+2*2)/1+1 =34 , 34 ,10]  \n",
    "        self.relu1 = nn.ReLU() # activation\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2) \n",
    "        # output_size =[ (34-2)/2+1 = 17, 17,10]  \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=5, kernel_size=3, stride=1)  \n",
    "        # output_size =[(17-3)/1+1 , 15 ,5] \n",
    "        self.relu2 = nn.ReLU() # activation\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 3, stride = 2) \n",
    "        # output_size =[(15-3)/2+1 , 7,5] \n",
    "        self.fc = nn.Linear(245,10)\n",
    "        \n",
    "                 \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        out = x.view(-1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        \n",
    "        return out\n",
    "    def retrieve_feature(self,x):\n",
    "        feature_map1 = self.relu1(x)\n",
    "        x = self.pool(x)\n",
    "        feature_map2 = self.relu1(x)\n",
    "        \n",
    "        return (feature_map1,feature_map2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c78f670",
   "metadata": {},
   "source": [
    "EPOCH = 1        # 跑完幾次所有batchsize              \n",
    "BATCH_SIZE = 50  # 一次訓練的樣本數目\n",
    "LR = 0.001       #學習率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "db945ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cnn_net()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461feb4",
   "metadata": {},
   "source": [
    "## 訓練資料集整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9ee76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9efd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e301bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:computervisionforcpuonpython3_7vy]",
   "language": "python",
   "name": "conda-env-computervisionforcpuonpython3_7vy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
